{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "139014c2",
   "metadata": {},
   "source": [
    "# Lofi Music Generator ðŸŽ¶\n",
    "\n",
    "## Basic Terminologies\n",
    "\n",
    "1. **Recurrent Neural Networks (RNN):** A recurrent neural network is a class of artificial neural networks that make use of sequential information. They are called recurrent because they perform the same function for every single element of a sequence, with the result being dependent on previous computations.\n",
    "\n",
    "2. **Long Short-Term Memory (LSTM):** A type of Recurrent Neural Network that can efficiently learn via gradient descent. Using a gating mechanism, LSTMs are able to recognise and encode long-term patterns. LSTMs are extremely useful to solve problems where the network has to remember information for a long period of time.\n",
    "\n",
    "3. **Music21:**  A Python toolkit used for computer-aided musicology. It allows us to teach the fundamentals of music theory, generate music examples and study music.\n",
    "\n",
    "4. **Keras:** A high-level neural networks API that simplifies interactions with Tensorflow.\n",
    "\n",
    "## Data Dictionary\n",
    "\n",
    "1. **Note:**  Note is a small bit of sound, similar to a syllable in spoken language.\n",
    "\n",
    "2. **Chord:**  Any harmonic set of pitches/frequencies consisting of multiple notes that are heard as if sounding simultaneously.\n",
    "\n",
    "3. **Pitch:** The frequency of the sound, or how high or low it is and is represented with the letters [A, B, C, D, E, F, G], with A being the highest and G being the lowest.\n",
    "\n",
    "4. **Octave:** Which set of pitches you use on a piano.\n",
    "\n",
    "5. **Offset:** Where the note is located in the piece.\n",
    "\n",
    "6. **Lofi Hip/Hop:** Lo-fi Hip Hop refers to a subliminal genre of music that fuses traditional hip-hop and jazz elements to create an atmospheric, soothing, instrumental soundscape. It is characterized by the high-utilization of elements such as introspection, mellow tunes, and Japanese anime."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b60792",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdb17645",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install music21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ba81bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "import tensorflow as tf\n",
    "import glob # Return all file paths that match a specific pattern.\n",
    "import pickle # serializing and de-serializing a Python object structure\n",
    "from music21 import converter, instrument, note, chord"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a188d198",
   "metadata": {},
   "source": [
    "### music21 \n",
    "\n",
    "1. **music21.converter** contains tools for loading music from various file formats, whether from disk, from the web, or from text, into music21.stream.:class:~music21.stream.Score objects (or other similar stream objects).\n",
    "\n",
    "2. **music21.instrument** represents instruments through objects that contain general information such as Metadata for instrument names, classifications, transpositions and default MIDI program numbers. It also contains information specific to each instrument or instrument family, such as string pitches, etc. \n",
    "\n",
    "3. **music21.note** contains classes and functions for creating Notes, Rests, and Lyrics.\n",
    "\n",
    "4. **music21.chord** defines the Chord object, a sub-class of GeneralNote as well as other methods, functions, and objects related to chords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26830c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notes(dir=None):\n",
    "    '''\n",
    "    Get all the notes and chords from the midi files in the directory\n",
    "    '''\n",
    "    notes = []\n",
    "    \n",
    "    filepaths = os.listdir(dir)\n",
    "    \n",
    "    for file in filepaths:\n",
    "        midi = converter.parse(dir+\"/\"+file) #loading each file into a Music21 stream object\n",
    "        parsed_note = None\n",
    "\n",
    "        try:    #file has instrument parts\n",
    "            meta = instrument.partitionByInstrument(midi)\n",
    "            parsed_note = meta.parts[0].recurse()\n",
    "        except: # file has notes in a flat structure\n",
    "            parsed_note = midi.flat.notes\n",
    "        \n",
    "        for element in parsed_note:\n",
    "            if isinstance(element, note.Note): #The isinstance() function returns True if the specified object is of the specified type, otherwise False.\n",
    "                notes.append(str(element.pitch))\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder)) #Chord.normalOrder Return the normal \n",
    "                                    #order/normal form of the Chord represented as a list of integers.\n",
    "                                    #append every chord by encoding the id of every note in the chord together into a single string, \n",
    "                                    #with each note being separated by a dot. \n",
    "                                    #These encodings allows us to easily decode the output generated by the network into the correct notes and chords.\n",
    "                                \n",
    "        with open('data/notes', 'wb') as filepath:\n",
    "            pickle.dump(notes, filepath)\n",
    "        \n",
    "    return notes\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b698d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = get_notes(\"Lofi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbe35dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence():\n",
    "    '''\n",
    "    create input sequences for the network and their respective outputs. \n",
    "    The output for each input sequence will be the first note or chord that \n",
    "    comes after the sequence of notes in the input sequence in our list of notes.\n",
    "    '''\n",
    "    sequence_len = 100\n",
    "\n",
    "    pitch = sorted(set(notes)) #get all pitches\n",
    "\n",
    "    # create a dictionary to map pitches to integers\n",
    "    int_note = dict((note, number) for number, note in enumerate(pitch))\n",
    "\n",
    "    net_in =  [] #Network Input\n",
    "    net_out = [] #Network Output\n",
    "\n",
    "    # create input and output sequences\n",
    "    for i in range(0, len(notes)-sequence_len):\n",
    "        seq_in   = notes[i:i+sequence_len]\n",
    "        seq_out  = notes[i+sequence_len]\n",
    "        \n",
    "        sequence=[]\n",
    "        for note in seq_in:\n",
    "            sequence.append(int_note[note])\n",
    "            \n",
    "        net_in.append(sequence)\n",
    "        net_out.append(int_note[seq_out])\n",
    "    \n",
    "    n_patterns=1800\n",
    "    \n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    net_in =  np.reshape(net_in, (n_patterns, sequence_len, 1))\n",
    "\n",
    "    # normalize input\n",
    "    #net_in = net_in / float(n_vocab)\n",
    "\n",
    "    net_out = tf.keras.utils.to_categorical(net_out) #Converts a class vector (integers) to binary class matrix.\n",
    "\n",
    "    return (net_in,net_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65b63085",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_in, net_out = sequence()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae969d8",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "In our model we use four different types of layers:\n",
    "\n",
    "**LSTM layers:** A Recurrent Neural Net layer that takes a sequence as an input and can return either sequences (return_sequences=True) or a matrix.\n",
    "\n",
    "\n",
    "**Dropout layers:** A regularisation technique that consists of setting a fraction of input units to 0 at each update during the training to prevent overfitting. The fraction is determined by the parameter used with the layer.\n",
    "\n",
    "\n",
    "**Dense layers:** A fully connected neural network layer where each input node is connected to each output node.\n",
    "\n",
    "\n",
    "**Activation layer:** Determines what activation function our neural network will use to calculate the output of a node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c46e9937",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(\n",
    "        units = 512, #Positive integer, dimensionality of the output space.\n",
    "        input_shape=(net_in.shape[1], net_in.shape[2]),\n",
    "        recurrent_dropout=0.3, # Fraction of the units to drop for the linear transformation of the recurrent state.\n",
    "        return_sequences=True # Whether to return the last output in the output sequence, or the full sequence.\n",
    "    ))\n",
    "    model.add(tf.keras.layers.LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\n",
    "    model.add(tf.keras.layers.LSTM(512))\n",
    "    model.add(tf.keras.layers.BatchNormalization()) #Layer that normalizes its inputs.\n",
    "    model.add(tf.keras.layers.Dropout(0.3)) #Applies Dropout to the input.\n",
    "    model.add(tf.keras.layers.Dense(254))\n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(0.3))\n",
    "    model.add(tf.keras.layers.Activation('softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5526985d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 100, 512)          1052672   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 100, 512)          2099200   \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 512)               2099200   \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512)              2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 254)               130302    \n",
      "                                                                 \n",
      " activation (Activation)     (None, 254)               0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 254)              1016      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 254)               0         \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 254)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,384,438\n",
      "Trainable params: 5,382,906\n",
      "Non-trainable params: 1,532\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ffad25f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, net_in, net_out):\n",
    "    '''\n",
    "    Training your neural network\n",
    "    '''\n",
    "    filepath=\"weights-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint( #Callback to save the Keras model or model weights at some frequency.\n",
    "        filepath,\n",
    "        monitor='loss',\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        mode='min'\n",
    "    )\n",
    "    callbacks_list = [checkpoint]\n",
    "    \n",
    "    model.fit(net_in, net_out, epochs=100, batch_size=128, callbacks=callbacks_list) #Train the model\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "98d35a49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 [==============================] - 638s 42s/step - loss: 5.1593\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 660s 44s/step - loss: 5.1567\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 659s 44s/step - loss: 5.0661\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 697s 46s/step - loss: 4.9903\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 702s 47s/step - loss: 4.9354\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 710s 47s/step - loss: 5.0251\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 728s 48s/step - loss: 4.9438\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 754s 50s/step - loss: 4.8491\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 734s 48s/step - loss: 4.7997\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 771s 51s/step - loss: 4.8141\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 833s 56s/step - loss: 4.7226\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 1010s 67s/step - loss: 4.6894\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 1073s 71s/step - loss: 4.7139\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 274s 17s/step - loss: 4.6088\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 288s 19s/step - loss: 4.5931\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 318s 21s/step - loss: 4.5334\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 320s 21s/step - loss: 4.4749\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 400s 26s/step - loss: 4.3961\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 429s 28s/step - loss: 4.3640\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 450s 30s/step - loss: 4.3220\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 433s 29s/step - loss: 4.2806\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 449s 30s/step - loss: 4.2503\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 463s 31s/step - loss: 4.1757\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 413s 27s/step - loss: 4.1175\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 564s 39s/step - loss: 4.0521\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 852s 56s/step - loss: 4.0723\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 834s 55s/step - loss: 3.9637\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 712s 47s/step - loss: 3.9352\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 722s 48s/step - loss: 3.8223\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 775s 52s/step - loss: 3.7826\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 829s 56s/step - loss: 3.6832\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 942s 63s/step - loss: 3.7023\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 955s 63s/step - loss: 3.6454\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 987s 65s/step - loss: 3.6640\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 931s 62s/step - loss: 3.6731\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 941s 62s/step - loss: 3.4547\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 657s 42s/step - loss: 3.4041\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 354s 24s/step - loss: 3.3714\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 419s 28s/step - loss: 3.2876\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 436s 29s/step - loss: 3.2588\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 427s 28s/step - loss: 3.2690\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 420s 28s/step - loss: 3.1200\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 389s 26s/step - loss: 3.1356\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 382s 25s/step - loss: 3.0344\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 373s 25s/step - loss: 2.9443\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 361s 24s/step - loss: 2.9194\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 343s 23s/step - loss: 2.9680\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 314s 21s/step - loss: 3.0011\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 337s 22s/step - loss: 2.8224\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 334s 22s/step - loss: 2.8284\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 332s 22s/step - loss: 2.8843\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 336s 22s/step - loss: 2.7635\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 507s 34s/step - loss: 2.7140\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 915s 61s/step - loss: 2.6232\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 929s 62s/step - loss: 2.6523\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 932s 62s/step - loss: 2.6527\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 892s 59s/step - loss: 2.6490\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 898s 60s/step - loss: 2.5859\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 894s 59s/step - loss: 2.4974\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 943s 63s/step - loss: 2.5422\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 614s 38s/step - loss: 2.5305\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 371s 25s/step - loss: 2.6199\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 380s 25s/step - loss: 2.5071\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 354s 24s/step - loss: 2.4084\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 358s 24s/step - loss: 2.4641\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 329s 22s/step - loss: 2.3809\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 324s 22s/step - loss: 2.3057\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 904s 60s/step - loss: 2.4704\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 912s 61s/step - loss: 2.3621\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 905s 60s/step - loss: 2.3076\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 908s 60s/step - loss: 2.3395\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 918s 61s/step - loss: 2.3366\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 910s 61s/step - loss: 2.2273\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 906s 60s/step - loss: 2.2452\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 921s 61s/step - loss: 2.2544\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 913s 60s/step - loss: 2.2796\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 957s 64s/step - loss: 2.1098\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 1175s 79s/step - loss: 2.3254\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 1134s 75s/step - loss: 2.1002\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 1130s 74s/step - loss: 2.2269\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 907s 58s/step - loss: 2.1295\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 305s 20s/step - loss: 2.1039\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 353s 24s/step - loss: 2.1228\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 365s 24s/step - loss: 2.0700\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 365s 24s/step - loss: 2.2034\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 368s 24s/step - loss: 2.1732\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 369s 24s/step - loss: 2.2211\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 368s 24s/step - loss: 2.1459\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 371s 25s/step - loss: 2.0022\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 370s 25s/step - loss: 2.1629\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 371s 25s/step - loss: 2.0950\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 747s 51s/step - loss: 1.9568\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 909s 60s/step - loss: 1.9348\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 900s 60s/step - loss: 1.9635\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 905s 60s/step - loss: 2.1434\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 908s 60s/step - loss: 1.9645\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 909s 60s/step - loss: 2.0851\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 921s 61s/step - loss: 2.0258\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 917s 61s/step - loss: 1.9373\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 925s 62s/step - loss: 2.0683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x136f206d070>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = train_model(model, net_in, net_out)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "64bd78ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f0110a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 100, 512)          1052672   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 100, 512)          2099200   \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 512)               2099200   \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512)              2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 254)               130302    \n",
      "                                                                 \n",
      " activation (Activation)     (None, 254)               0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 254)              1016      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 254)               0         \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 254)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,384,438\n",
      "Trainable params: 5,382,906\n",
      "Non-trainable params: 1,532\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model = tf.keras.models.load_model('models')\n",
    "# model.summary()\n",
    "\n",
    "model = create_network(net_in, 100)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d7505bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_weights(network_input, n_vocab):\n",
    "    \"\"\" \n",
    "    create the structure of the neural network \n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(\n",
    "        units = 512, #Positive integer, dimensionality of the output space.\n",
    "        input_shape=(net_in.shape[1], net_in.shape[2]),\n",
    "        recurrent_dropout=0.3, # Fraction of the units to drop for the linear transformation of the recurrent state.\n",
    "        return_sequences=True # Whether to return the last output in the output sequence, or the full sequence.\n",
    "    ))\n",
    "    model.add(tf.keras.layers.LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\n",
    "    model.add(tf.keras.layers.LSTM(512))\n",
    "    model.add(tf.keras.layers.BatchNormalization()) #Layer that normalizes its inputs.\n",
    "    model.add(tf.keras.layers.Dropout(0.3)) #Applies Dropout to the input.\n",
    "    model.add(tf.keras.layers.Dense(254))\n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(0.3))\n",
    "    model.add(tf.keras.layers.Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "    # Load the weights to each node\n",
    "    model.load_weights('weights-93-1.9348-bigger.hdf5')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96203241",
   "metadata": {},
   "source": [
    "## Generate Song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ae517057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_notes(model, network_input, notes, n_vocab):\n",
    "    \"\"\" \n",
    "    Generate notes from the neural network based on a sequence of notes \n",
    "    \"\"\"\n",
    "    \n",
    "    # pick a random sequence from the input as a starting point for the prediction\n",
    "    start = np.random.randint(0, len(network_input)-1)\n",
    "    pitch = sorted(set(notes))\n",
    "    \n",
    "\n",
    "    int_to_note = dict((number, note) for number, note in enumerate(pitch))\n",
    "\n",
    "    pattern = network_input[start]\n",
    "    prediction_output = []\n",
    "\n",
    "    # generate 500 notes\n",
    "    prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    prediction_input = prediction_input / float(n_vocab)\n",
    "        \n",
    "    predictions = model.predict(net_in[100:400], verbose=0)\n",
    "    for i in range(len(predictions)):\n",
    "        index = np.argmax(predictions[i])\n",
    "        result = int_to_note[index]\n",
    "        prediction_output.append(result)\n",
    "\n",
    "    return prediction_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "c4edbad0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6.9.11.2', 'F#4', 'F#5', 'E5', 'G5', 'B5', '4.7.11', 'E4', 'G4', 'E5', '6.9.11.2', 'F#4', 'F#5', 'E5', 'G5', 'B5', '4.7.11', 'E4', 'G4', 'A5', '6.9.11.2', 'A4', '4.5.9.0', 'A4', '2.4.7.9', '4.7.9.0', 'A4', '4.7.9.11.0', 'E4', 'G4', 'A5', 'E5', 'A4', '4.5.9.0', 'A4', '2.4.7.9', '4.7.9.0', 'A4', '5.9.0', 'E4', 'G6', 'A5', 'E6', 'A5', 'G5', 'D6', 'E5', '11.0', '4.7', 'E5', 'E4', 'G5', 'G3', 'C5', 'D5', '5.9.0', 'E4', 'G6', 'F6', 'E6', 'A5', 'G5', 'D6', 'E5', '11.0', '4.7', 'E5', 'E4', 'G5', 'G3', 'C5', 'D5', '0.1.3.5.8', 'G#5', 'G5', 'E-5', 'C5', '0.1.3.5.8', 'C5', 'B-4', 'C5', '3.7.10', 'E-5', 'C5', '0.3.5.8', 'G#5', '0.3.5.7.8', 'G5', 'E-5', 'C5', '0.3.5.7.8', 'C5', 'B-4', '7.8.10.0.3', '7.8.10.0.3', 'B-5', 'C6', '4.6.9.11', '1', '11', '9.11.1.4', 'C#4', '9.11.1.4', '8.11.1.4', '1', '7.10.0.3', 'C#4', 'B1', '2.6.9', '4', 'C#4', '11', 'B1', '2.6.9', 'C#4', 'D2', '6.9.1', 'C#4', 'C#4', '9', '4.6.9.11', '1', '11', '9.11.1.4', 'C#4', '9.11.1.4', '8.11.1.4', '1', '7.10.0.3', 'C#4', 'B1', '2.6.9', '4', 'C#4', '6', 'B1', '2.6.9', 'C#4', 'D2', '6.9.1', '1.4', '9.1', '4.5.9.0', '4.5.9.0', 'C5', 'E5', 'D5', 'B4', '11.0', 'G4', '9.0.2.5', 'G4', '9.0.2.5', 'G4', 'E4', '2.7', 'A4', 'C5', '4.5.9.0', '4.5.9.0', 'C5', 'E5', 'D5', 'B4', '7.0', 'E5', '9.0.2.5', 'E5', '9.0.2.5', 'E5', 'D5', '2.7', '2.5.9', 'A4', 'C5', 'B3', 'B4', 'B4', 'G3', 'A4', 'B4', 'G4', 'B4', '11.0.4.7', '2.7', 'B4', 'E4', 'C4', 'F4', 'C4', '8.11.3', 'F4', 'F4', '5.7', 'E4', 'C6', '5.9.0', '9.0.4', 'D6', 'C6', 'A5', 'B5', '0.4', '11.2.4', 'A5', 'G4', '11.2', '11.2.4', 'G4', '11.2', '7.0', 'E5', 'E4', 'B4', '4.5.9.0', 'E5', 'B4', 'A5', 'B5', 'C6', 'A5', '11.2.4.7', 'F5', 'G5', '11.2.4.7', 'F5', '4.7', '9.0.4', '9.0', 'D5', 'E5', 'D5', 'C5', 'C3', 'E-5', '10.0', '3.7', '2.3.7', 'A4', '5.9', '3.5', '0.3.5', 'A2', 'D3', 'A4', 'C4', '0.5', 'F#3', '5.7', '7.11', '2.5.7', 'B2', 'C3', '10.0', '3.7', '2.3.7', 'A4', '5.9', '3.5', '0.3.5', 'A2', '9.2', 'C4', '0.5', 'F#3', '5.7', '7.11', '2.5.7', 'G5', '5.11', '10.0', '0.3.7', '0.2.3.7', '0.2.3.7', 'E-2', '3.5', 'A3', '0.3.5', '0.3.5', 'E-2', '0.2', 'F3', 'A3', '0.2', '0.2.5', 'F#2', '5.7', 'B3', '2.7', '5.7', 'F3', '3.7', '3.5.7', '7.9.10.0.3', 'F#4', '10.0.3', '6.8', 'F#4', 'F4', '5.9.10.0']\n"
     ]
    }
   ],
   "source": [
    "generated_notes = generate_notes(model, net_in, notes, 100)\n",
    "print(generated_notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213b5c1f",
   "metadata": {},
   "source": [
    "## Stream Music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "50c3b804",
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import stream\n",
    "\n",
    "def create_midi(prediction_output):\n",
    "    \"\"\" \n",
    "    convert the output from the prediction to notes and create a midi file\n",
    "    from the notes \n",
    "    \"\"\"\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                new_note = note.Note(int(current_note))\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "        # pattern is a note\n",
    "        else:\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 0.5\n",
    "\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "\n",
    "    midi_stream.write('midi', fp='test_output3.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f5f25b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_midi(generated_notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790b9446",
   "metadata": {},
   "source": [
    "# AI Generated Song"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f383da3",
   "metadata": {},
   "source": [
    "https://soundcloud.com/user-467169078/ai-lofi?utm_source=clipboard&utm_medium=text&utm_campaign=social_sharing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
